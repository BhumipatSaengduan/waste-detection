{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Waste Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Firstly, Download the PyTorch before Ultralytics if we want to use CUDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyTorch (CUDA): https://pytorch.org/get-started/locally/\n",
    "%pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, Install neccesary packages:\n",
    "- `numpy`\n",
    "- `opencv-python`: reading image with opencv to inference and draw any bounding boxes\n",
    "- `ultralytics`: a YOLO weight loader\n",
    "- `matplotlib`: an alternative to opencv for display images in this case.\n",
    "- `inflection`: a utility package for converting dataset\n",
    "- `pyyaml`: a utility package for construct dataset\n",
    "- `scikit-learn`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "%pip install numpy opencv-python ultralytics matplotlib inflection pyyaml scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Dataset\n",
    "\n",
    "The dataset will be used is [TACO](http://tacodataset.org/), (Trash Annotations in Context) which is an open image dataset of waste. The  annotations are provided in COCO format which means we need to convert it to the YOLO format."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create directories (if not exists) for YOLO dataset and a folder for images to be downloaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "cwd = Path.cwd()\n",
    "\n",
    "DATASET_PATH = cwd / 'dataset'\n",
    "\n",
    "ORIGINAL_DATASET_PATH = DATASET_PATH / 'original'\n",
    "\n",
    "ORIGINAL_IMAGES_PATH = ORIGINAL_DATASET_PATH / 'images'\n",
    "ORIGINAL_INFO_PATH = ORIGINAL_DATASET_PATH / 'annotations.json'\n",
    "\n",
    "YOLO_DATASET_PATH = DATASET_PATH / 'yolo'\n",
    "\n",
    "TRAIN_DIR = 'train'\n",
    "TRAIN_IMAGES_PATH = YOLO_DATASET_PATH / 'images' / TRAIN_DIR\n",
    "TRAIN_LABELS_PATH = YOLO_DATASET_PATH / 'labels' / TRAIN_DIR\n",
    "\n",
    "TEST_DIR = 'test'\n",
    "TEST_IMAGES_PATH = YOLO_DATASET_PATH / 'images' / TEST_DIR\n",
    "TEST_LABELS_PATH = YOLO_DATASET_PATH / 'labels' / TEST_DIR\n",
    "\n",
    "VALIDATION_DIR = 'val'\n",
    "VALIDATION_IMAGES_PATH = YOLO_DATASET_PATH / 'images' / VALIDATION_DIR\n",
    "VALIDATION_LABELS_PATH = YOLO_DATASET_PATH / 'labels' / VALIDATION_DIR\n",
    "\n",
    "for dir in [ORIGINAL_DATASET_PATH, ORIGINAL_IMAGES_PATH,\n",
    "            TRAIN_IMAGES_PATH, TRAIN_LABELS_PATH,\n",
    "            TEST_IMAGES_PATH, TEST_LABELS_PATH,\n",
    "            VALIDATION_IMAGES_PATH, VALIDATION_LABELS_PATH]:\n",
    "    # create directories if not exist\n",
    "    os.makedirs(dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download original annotations and dataset information from [TACO](https://github.com/pedropro/TACO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlretrieve\n",
    "\n",
    "# https://github.com/pedropro/TACO\n",
    "DATASET_URL = 'https://raw.githubusercontent.com/pedropro/TACO/refs/heads/master/data/annotations.json'\n",
    "\n",
    "urlretrieve(DATASET_URL, ORIGINAL_INFO_PATH)\n",
    "\n",
    "print('dataset information downloaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parses dataset information. (JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(ORIGINAL_INFO_PATH) as json_data:\n",
    "    dataset_info = json.load(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download images to `dataset/original/images`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import splitext\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "images = []\n",
    "for image in dataset_info['images']:\n",
    "    url = image['flickr_url']\n",
    "    _, file_ext = splitext(urlparse(url).path)  # get url's file extension\n",
    "\n",
    "    # get file name and file path\n",
    "    file_name = f'{image['id']}{file_ext}'\n",
    "    image_path = ORIGINAL_IMAGES_PATH / file_name\n",
    "\n",
    "    images.append({\n",
    "        'id': image['id'],\n",
    "        'file_name': file_name,\n",
    "        'file_path': image_path,\n",
    "        'width': image['width'],\n",
    "        'height': image['height'],\n",
    "        'url': url,\n",
    "        'labels': [],\n",
    "    })\n",
    "\n",
    "print('total image count:', len(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download all images in parallel with exponential backoff for rate-limited cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import random\n",
    "from time import sleep\n",
    "from urllib.error import HTTPError\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "MAX_BACKOFF = 3 * 60  # 3min\n",
    "\n",
    "def download_image(image):\n",
    "    if not image['file_path'].exists():\n",
    "        retries = 0\n",
    "        while True:  # infinite loop for retries\n",
    "            try:\n",
    "                # download image\n",
    "                urlretrieve(image['url'], image['file_path'])\n",
    "                print(f'Downloaded: {image[\"file_name\"]}')\n",
    "                break\n",
    "            except HTTPError as e:\n",
    "                # if got rate-limited\n",
    "                if e.status == 429:  \n",
    "                    # exponential backoff\n",
    "                    delay = min((2 ** retries + random.uniform(0, 1)), MAX_BACKOFF)\n",
    "                    sleep(delay)\n",
    "\n",
    "                    if retries > 4:\n",
    "                        print(f'{image[\"file_path\"]}: rate limited: retries={retries}')\n",
    "                    retries += 1\n",
    "                else:\n",
    "                    raise e\n",
    "\n",
    "# parallel download using ThreadPoolExecutor\n",
    "with ThreadPoolExecutor() as executor:\n",
    "    executor.map(download_image, images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepares data for YOLO.\n",
    "\n",
    "1. Get super-categories from categories in the dataset information.\n",
    "\n",
    "2. Put all super-categories in to a list for future use in YOLO dataset format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from inflection import underscore\n",
    "\n",
    "def to_snake_case(string):\n",
    "    string = string.replace(' ', '_').replace('&', 'and')\n",
    "    string = underscore(string)\n",
    "    return string\n",
    "\n",
    "classes = []\n",
    "for category in dataset_info['categories']:\n",
    "    supercategory = category['supercategory']\n",
    "\n",
    "    # convert to snake case\n",
    "    supercategory = to_snake_case(supercategory)\n",
    "\n",
    "    if supercategory not in classes:\n",
    "        classes.append(supercategory)\n",
    "\n",
    "def as_class_id(category_id):\n",
    "    category = to_snake_case(dataset_info['categories'][category_id]['supercategory'])\n",
    "    class_id = classes.index(category)\n",
    "    return (class_id, classes[class_id])\n",
    "\n",
    "print('total classes:', len(classes))\n",
    "print('classes:', ', '.join(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Convert COCO format into YOLO format. (`class_id x_center y_center width height`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coco_to_yolo(x, y, w, h, img_w, img_h):\n",
    "    x_center = (x + w / 2) / img_w\n",
    "    y_center = (y + h / 2) / img_h\n",
    "    width = w / img_w\n",
    "    height = h / img_h\n",
    "    return (x_center, y_center, width, height)\n",
    "\n",
    "\n",
    "# clear labels\n",
    "for image in images:\n",
    "    image['labels'] = []\n",
    "\n",
    "for annotation in dataset_info['annotations']:\n",
    "    data = images[annotation['image_id']]\n",
    "    \n",
    "    img_w = data['width']\n",
    "    img_h = data['height']\n",
    "\n",
    "    class_id, _ = as_class_id(annotation['category_id'])\n",
    "\n",
    "    x, y, w, h = annotation['bbox']\n",
    "    x, y, w, h = coco_to_yolo(x, y, w, h, img_w, img_h)\n",
    "\n",
    "    yolo_line = f'{class_id} {x} {y} {w} {h}'\n",
    "\n",
    "    data['labels'] += [yolo_line]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Filter images with annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = [image for image in images if len(image['labels']) > 0]\n",
    "print('total valid image and annotation count:', len(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Use `train_test_split` from `scikit-learn` to split train/test/validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "image_ids = list(range(len(images)))\n",
    "\n",
    "train_data, temp_data = train_test_split(image_ids, test_size=0.3, shuffle=True)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.5, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Remove all existing images and labels in the YOLO dataset directory.\n",
    "\n",
    "7. Copy images from original to the YOLO directory according to the train/test/dataset split.\n",
    "\n",
    "8. Write transformed labels to the YOLO directory according to the train/test/dataset split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# delete all files in the current yolo folder\n",
    "for dir in [TRAIN_IMAGES_PATH, TRAIN_LABELS_PATH,\n",
    "            TEST_IMAGES_PATH, TEST_LABELS_PATH,\n",
    "            VALIDATION_IMAGES_PATH, VALIDATION_LABELS_PATH]:\n",
    "    for f in os.listdir(dir):\n",
    "        if os.path.isfile(dir / f):\n",
    "            os.remove(dir / f)\n",
    "\n",
    "# copy images and annotations to each corresponding train/test/validation folder.\n",
    "for data_list, img_dir, label_dir in [\n",
    "        (train_data, TRAIN_IMAGES_PATH, TRAIN_LABELS_PATH),\n",
    "        (test_data, TEST_IMAGES_PATH, TEST_LABELS_PATH),\n",
    "        (val_data, VALIDATION_IMAGES_PATH, VALIDATION_LABELS_PATH),\n",
    "    ]:\n",
    "    for data_id in data_list:\n",
    "        data = images[data_id]\n",
    "\n",
    "        # copy image to the folder\n",
    "        shutil.copy(data['file_path'], img_dir / data['file_name'])\n",
    "        \n",
    "        # write yolo labels to a file\n",
    "        file_name = data['file_path'].stem\n",
    "        with open(label_dir / f'{file_name}.txt', 'w') as f:\n",
    "            f.write('\\n'.join(data['labels']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Create a YAML file for YOLO to works with, define dataset path, train/test/validation path, class count, and class names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "DATASET_YAML = YOLO_DATASET_PATH / 'taco.yaml'\n",
    "\n",
    "content = {\n",
    "    'path': str(YOLO_DATASET_PATH),\n",
    "    'train': 'images/train',\n",
    "    'test': 'images/test',\n",
    "    'val': 'images/val',\n",
    "\n",
    "    'nc': len(classes),\n",
    "    'names': classes\n",
    "}\n",
    "with open(DATASET_YAML, 'w') as f:\n",
    "    yaml.dump(content, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize YOLO object with YOLOv11 weight. (the object will automatically download the weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('yolo11n.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with dataset at 30 epochs using CUDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results = model.train(\n",
    "    data=DATASET_YAML,  # dataset\n",
    "    epochs=30,          # epochs\n",
    "    imgsz=640,          # image size\n",
    "    batch=8,            # batch size\n",
    "    device=0,           # device to train (cpu or gpu)\n",
    "    save=True           # save the model as a weight file\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick 16 random images from validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import cv2\n",
    "\n",
    "inference_imgs = [cv2.imread(images[i]['file_path']) for i in random.sample(val_data, 16)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.predict(inference_imgs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Draw classes and bounding boxes on the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "WIDTH = 20\n",
    "FONT_SCALE = 6\n",
    "\n",
    "bbox_imgs = []\n",
    "for result in results:\n",
    "    image = cv2.cvtColor(result.orig_img, cv2.COLOR_BGR2RGB)\n",
    "    for box in result.boxes:\n",
    "        x1, y1, x2, y2 = box.xyxy[0].cpu().numpy().astype(np.int32)  # get bounding box\n",
    "        cls = box.cls.cpu().numpy().astype(np.int32)[0]       # get class id\n",
    "        cls = result.names[cls]                               # get class name from the id\n",
    "\n",
    "        color = (\n",
    "            random.randint(0, 255),\n",
    "            random.randint(0, 255),\n",
    "            random.randint(0, 255)\n",
    "        )\n",
    "\n",
    "\n",
    "        # draw a bounding box\n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), color, WIDTH)  \n",
    "        # write a class name to the box\n",
    "        cv2.putText(image, cls, (x1, y1 - 10),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, FONT_SCALE,\n",
    "                    color, WIDTH)\n",
    "\n",
    "    bbox_imgs.append(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Display the images on 4x4 matplotlib plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
    "for idx, ax in enumerate(axes.ravel()):\n",
    "    img = bbox_imgs[idx]\n",
    "    ax.imshow(img)\n",
    "    ax.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "# plt.savefig('output.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
